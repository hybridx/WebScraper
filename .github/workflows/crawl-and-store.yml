name: ğŸ•·ï¸ Crawl and Store Files

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'URL to crawl'
        required: true
        type: string
      source:
        description: 'Source (app or manual)'
        default: 'manual'
        type: string
      recursive:
        description: 'Enable recursive crawling'
        default: true
        type: boolean
      max_depth:
        description: 'Maximum crawl depth (1-5)'
        default: '3'
        type: choice
        options:
          - '1'
          - '2'
          - '3'
          - '4'
          - '5'
  repository_dispatch:
    types: [crawl-request]

jobs:
  crawl:
    runs-on: ubuntu-latest
    name: ğŸš€ Crawl Directory and Store Files
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4
        
      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          
      - name: ğŸ”§ Install dependencies
        run: npm ci
        
      - name: ğŸ” Debug environment variables
        run: |
          echo "Checking environment variables..."
          echo "SUPABASE_URL length: ${#NEXT_PUBLIC_SUPABASE_URL}"
          echo "SUPABASE_KEY length: ${#NEXT_PUBLIC_SUPABASE_ANON_KEY}"
          echo "CRAWL_URL: $CRAWL_URL"
          echo "RECURSIVE: $RECURSIVE"
          echo "MAX_DEPTH: $MAX_DEPTH"
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          CRAWL_URL: ${{ github.event.inputs.url || github.event.client_payload.url }}
          RECURSIVE: ${{ github.event.inputs.recursive || github.event.client_payload.recursive || 'true' }}
          MAX_DEPTH: ${{ github.event.inputs.max_depth || github.event.client_payload.max_depth || '3' }}
          
      - name: ğŸ•·ï¸ Run crawler
        run: node scripts/github-crawler.js
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          CRAWL_URL: ${{ github.event.inputs.url || github.event.client_payload.url }}
          SOURCE: ${{ github.event.inputs.source || github.event.client_payload.source }}
          RECURSIVE: ${{ github.event.inputs.recursive || github.event.client_payload.recursive || 'true' }}
          MAX_DEPTH: ${{ github.event.inputs.max_depth || github.event.client_payload.max_depth || '3' }}
          
      - name: ğŸ“Š Display results
        run: |
          echo "âœ… Crawl completed successfully!"
          echo "ğŸ”— URL: ${{ github.event.inputs.url || github.event.client_payload.url }}"
          echo "ğŸ“± Source: ${{ github.event.inputs.source || github.event.client_payload.source }}"
          echo "ğŸ”„ Recursive: ${{ github.event.inputs.recursive || github.event.client_payload.recursive || 'true' }}"
          echo "ğŸ“ Max Depth: ${{ github.event.inputs.max_depth || github.event.client_payload.max_depth || '3' }}" 